{
    "hidden_dim": 768,
    "n_layers": 12,
    "n_heads": 12,
    "seq_len": 4112,
    "vocab_size": 16448,
    "post_embed_norm": false,
    "weight_tying": false
}
